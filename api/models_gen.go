// Code generated by github.com/99designs/gqlgen, DO NOT EDIT.

package api

import (
	"fmt"
	"io"
	"strconv"
	"time"
)

// expression to compare columns of type bigint. All fields are combined with logical 'AND'.
type BigintComparisonExp struct {
	_eq     *int64   `json:"_eq"`
	_gt     *int64   `json:"_gt"`
	_gte    *int64   `json:"_gte"`
	_in     []*int64 `json:"_in"`
	_isNull *bool    `json:"_is_null"`
	_lt     *int64   `json:"_lt"`
	_lte    *int64   `json:"_lte"`
	_neq    *int64   `json:"_neq"`
	_nin    []*int64 `json:"_nin"`
}

// expression to compare columns of type boolean. All fields are combined with logical 'AND'.
type BooleanComparisonExp struct {
	_eq     *bool   `json:"_eq"`
	_gt     *bool   `json:"_gt"`
	_gte    *bool   `json:"_gte"`
	_in     []*bool `json:"_in"`
	_isNull *bool   `json:"_is_null"`
	_lt     *bool   `json:"_lt"`
	_lte    *bool   `json:"_lte"`
	_neq    *bool   `json:"_neq"`
	_nin    []*bool `json:"_nin"`
}

// columns and relationships of "domain_users"
type DomainUsers struct {
	Groups   string `json:"groups"`
	Name     string `json:"name"`
	Sid      string `json:"sid"`
	Username string `json:"username"`
}

// aggregated selection of "domain_users"
type DomainUsersAggregate struct {
	Aggregate *DomainUsersAggregateFields `json:"aggregate"`
	Nodes     []*DomainUsers              `json:"nodes"`
}

// aggregate fields of "domain_users"
type DomainUsersAggregateFields struct {
	Count *int                  `json:"count"`
	Max   *DomainUsersMaxFields `json:"max"`
	Min   *DomainUsersMinFields `json:"min"`
}

// order by aggregate values of table "domain_users"
type DomainUsersAggregateOrderBy struct {
	Count *OrderBy               `json:"count"`
	Max   *DomainUsersMaxOrderBy `json:"max"`
	Min   *DomainUsersMinOrderBy `json:"min"`
}

// append existing jsonb value of filtered columns with new jsonb value
type DomainUsersAppendInput struct {
	Groups *string `json:"groups"`
}

// input type for inserting array relation for remote table "domain_users"
type DomainUsersArrRelInsertInput struct {
	Data       []*DomainUsersInsertInput `json:"data"`
	OnConflict *DomainUsersOnConflict    `json:"on_conflict"`
}

// Boolean expression to filter rows from the table "domain_users". All fields are combined with a logical 'AND'.
type DomainUsersBoolExp struct {
	_and     []*DomainUsersBoolExp `json:"_and"`
	_not     *DomainUsersBoolExp   `json:"_not"`
	_or      []*DomainUsersBoolExp `json:"_or"`
	Groups   *JsonbComparisonExp   `json:"groups"`
	Name     *TextComparisonExp    `json:"name"`
	Sid      *TextComparisonExp    `json:"sid"`
	Username *TextComparisonExp    `json:"username"`
}

// delete the field or element with specified path (for JSON arrays, negative integers count from the end)
type DomainUsersDeleteAtPathInput struct {
	Groups []*string `json:"groups"`
}

// delete the array element with specified index (negative integers count from the
// end). throws an error if top level container is not an array
type DomainUsersDeleteElemInput struct {
	Groups *int `json:"groups"`
}

// delete key/value pair or string element. key/value pairs are matched based on their key value
type DomainUsersDeleteKeyInput struct {
	Groups *string `json:"groups"`
}

// input type for inserting data into table "domain_users"
type DomainUsersInsertInput struct {
	Groups   *string `json:"groups"`
	Name     *string `json:"name"`
	Sid      *string `json:"sid"`
	Username *string `json:"username"`
}

// aggregate max on columns
type DomainUsersMaxFields struct {
	Name     *string `json:"name"`
	Sid      *string `json:"sid"`
	Username *string `json:"username"`
}

// order by max() on columns of table "domain_users"
type DomainUsersMaxOrderBy struct {
	Name     *OrderBy `json:"name"`
	Sid      *OrderBy `json:"sid"`
	Username *OrderBy `json:"username"`
}

// aggregate min on columns
type DomainUsersMinFields struct {
	Name     *string `json:"name"`
	Sid      *string `json:"sid"`
	Username *string `json:"username"`
}

// order by min() on columns of table "domain_users"
type DomainUsersMinOrderBy struct {
	Name     *OrderBy `json:"name"`
	Sid      *OrderBy `json:"sid"`
	Username *OrderBy `json:"username"`
}

// response of any mutation on the table "domain_users"
type DomainUsersMutationResponse struct {
	// number of affected rows by the mutation
	AffectedRows int `json:"affected_rows"`
	// data of the affected rows by the mutation
	Returning []*DomainUsers `json:"returning"`
}

// input type for inserting object relation for remote table "domain_users"
type DomainUsersObjRelInsertInput struct {
	Data       *DomainUsersInsertInput `json:"data"`
	OnConflict *DomainUsersOnConflict  `json:"on_conflict"`
}

// on conflict condition type for table "domain_users"
type DomainUsersOnConflict struct {
	Constraint    DomainUsersConstraint     `json:"constraint"`
	UpdateColumns []DomainUsersUpdateColumn `json:"update_columns"`
}

// ordering options when selecting data from "domain_users"
type DomainUsersOrderBy struct {
	Groups   *OrderBy `json:"groups"`
	Name     *OrderBy `json:"name"`
	Sid      *OrderBy `json:"sid"`
	Username *OrderBy `json:"username"`
}

// prepend existing jsonb value of filtered columns with new jsonb value
type DomainUsersPrependInput struct {
	Groups *string `json:"groups"`
}

// input type for updating data in table "domain_users"
type DomainUsersSetInput struct {
	Groups   *string `json:"groups"`
	Name     *string `json:"name"`
	Sid      *string `json:"sid"`
	Username *string `json:"username"`
}

// columns and relationships of "endpoints"
type Endpoints struct {
	EndpointID int    `json:"endpoint_id"`
	Ignore     bool   `json:"ignore"`
	Path       string `json:"path"`
	Principal  *int   `json:"principal"`
}

// aggregated selection of "endpoints"
type EndpointsAggregate struct {
	Aggregate *EndpointsAggregateFields `json:"aggregate"`
	Nodes     []*Endpoints              `json:"nodes"`
}

// aggregate fields of "endpoints"
type EndpointsAggregateFields struct {
	Avg        *EndpointsAvgFields        `json:"avg"`
	Count      *int                       `json:"count"`
	Max        *EndpointsMaxFields        `json:"max"`
	Min        *EndpointsMinFields        `json:"min"`
	Stddev     *EndpointsStddevFields     `json:"stddev"`
	StddevPop  *EndpointsStddevPopFields  `json:"stddev_pop"`
	StddevSamp *EndpointsStddevSampFields `json:"stddev_samp"`
	Sum        *EndpointsSumFields        `json:"sum"`
	VarPop     *EndpointsVarPopFields     `json:"var_pop"`
	VarSamp    *EndpointsVarSampFields    `json:"var_samp"`
	Variance   *EndpointsVarianceFields   `json:"variance"`
}

// order by aggregate values of table "endpoints"
type EndpointsAggregateOrderBy struct {
	Avg        *EndpointsAvgOrderBy        `json:"avg"`
	Count      *OrderBy                    `json:"count"`
	Max        *EndpointsMaxOrderBy        `json:"max"`
	Min        *EndpointsMinOrderBy        `json:"min"`
	Stddev     *EndpointsStddevOrderBy     `json:"stddev"`
	StddevPop  *EndpointsStddevPopOrderBy  `json:"stddev_pop"`
	StddevSamp *EndpointsStddevSampOrderBy `json:"stddev_samp"`
	Sum        *EndpointsSumOrderBy        `json:"sum"`
	VarPop     *EndpointsVarPopOrderBy     `json:"var_pop"`
	VarSamp    *EndpointsVarSampOrderBy    `json:"var_samp"`
	Variance   *EndpointsVarianceOrderBy   `json:"variance"`
}

// input type for inserting array relation for remote table "endpoints"
type EndpointsArrRelInsertInput struct {
	Data       []*EndpointsInsertInput `json:"data"`
	OnConflict *EndpointsOnConflict    `json:"on_conflict"`
}

// aggregate avg on columns
type EndpointsAvgFields struct {
	EndpointID *float64 `json:"endpoint_id"`
	Principal  *float64 `json:"principal"`
}

// order by avg() on columns of table "endpoints"
type EndpointsAvgOrderBy struct {
	EndpointID *OrderBy `json:"endpoint_id"`
	Principal  *OrderBy `json:"principal"`
}

// Boolean expression to filter rows from the table "endpoints". All fields are combined with a logical 'AND'.
type EndpointsBoolExp struct {
	_and       []*EndpointsBoolExp   `json:"_and"`
	_not       *EndpointsBoolExp     `json:"_not"`
	_or        []*EndpointsBoolExp   `json:"_or"`
	EndpointID *IntegerComparisonExp `json:"endpoint_id"`
	Ignore     *BooleanComparisonExp `json:"ignore"`
	Path       *TextComparisonExp    `json:"path"`
	Principal  *IntegerComparisonExp `json:"principal"`
}

// input type for incrementing integer columne in table "endpoints"
type EndpointsIncInput struct {
	EndpointID *int `json:"endpoint_id"`
	Principal  *int `json:"principal"`
}

// input type for inserting data into table "endpoints"
type EndpointsInsertInput struct {
	EndpointID *int    `json:"endpoint_id"`
	Ignore     *bool   `json:"ignore"`
	Path       *string `json:"path"`
	Principal  *int    `json:"principal"`
}

// aggregate max on columns
type EndpointsMaxFields struct {
	EndpointID *int    `json:"endpoint_id"`
	Path       *string `json:"path"`
	Principal  *int    `json:"principal"`
}

// order by max() on columns of table "endpoints"
type EndpointsMaxOrderBy struct {
	EndpointID *OrderBy `json:"endpoint_id"`
	Path       *OrderBy `json:"path"`
	Principal  *OrderBy `json:"principal"`
}

// aggregate min on columns
type EndpointsMinFields struct {
	EndpointID *int    `json:"endpoint_id"`
	Path       *string `json:"path"`
	Principal  *int    `json:"principal"`
}

// order by min() on columns of table "endpoints"
type EndpointsMinOrderBy struct {
	EndpointID *OrderBy `json:"endpoint_id"`
	Path       *OrderBy `json:"path"`
	Principal  *OrderBy `json:"principal"`
}

// response of any mutation on the table "endpoints"
type EndpointsMutationResponse struct {
	// number of affected rows by the mutation
	AffectedRows int `json:"affected_rows"`
	// data of the affected rows by the mutation
	Returning []*Endpoints `json:"returning"`
}

// input type for inserting object relation for remote table "endpoints"
type EndpointsObjRelInsertInput struct {
	Data       *EndpointsInsertInput `json:"data"`
	OnConflict *EndpointsOnConflict  `json:"on_conflict"`
}

// on conflict condition type for table "endpoints"
type EndpointsOnConflict struct {
	Constraint    EndpointsConstraint     `json:"constraint"`
	UpdateColumns []EndpointsUpdateColumn `json:"update_columns"`
}

// ordering options when selecting data from "endpoints"
type EndpointsOrderBy struct {
	EndpointID *OrderBy `json:"endpoint_id"`
	Ignore     *OrderBy `json:"ignore"`
	Path       *OrderBy `json:"path"`
	Principal  *OrderBy `json:"principal"`
}

// input type for updating data in table "endpoints"
type EndpointsSetInput struct {
	EndpointID *int    `json:"endpoint_id"`
	Ignore     *bool   `json:"ignore"`
	Path       *string `json:"path"`
	Principal  *int    `json:"principal"`
}

// aggregate stddev on columns
type EndpointsStddevFields struct {
	EndpointID *float64 `json:"endpoint_id"`
	Principal  *float64 `json:"principal"`
}

// order by stddev() on columns of table "endpoints"
type EndpointsStddevOrderBy struct {
	EndpointID *OrderBy `json:"endpoint_id"`
	Principal  *OrderBy `json:"principal"`
}

// aggregate stddev_pop on columns
type EndpointsStddevPopFields struct {
	EndpointID *float64 `json:"endpoint_id"`
	Principal  *float64 `json:"principal"`
}

// order by stddev_pop() on columns of table "endpoints"
type EndpointsStddevPopOrderBy struct {
	EndpointID *OrderBy `json:"endpoint_id"`
	Principal  *OrderBy `json:"principal"`
}

// aggregate stddev_samp on columns
type EndpointsStddevSampFields struct {
	EndpointID *float64 `json:"endpoint_id"`
	Principal  *float64 `json:"principal"`
}

// order by stddev_samp() on columns of table "endpoints"
type EndpointsStddevSampOrderBy struct {
	EndpointID *OrderBy `json:"endpoint_id"`
	Principal  *OrderBy `json:"principal"`
}

// aggregate sum on columns
type EndpointsSumFields struct {
	EndpointID *int `json:"endpoint_id"`
	Principal  *int `json:"principal"`
}

// order by sum() on columns of table "endpoints"
type EndpointsSumOrderBy struct {
	EndpointID *OrderBy `json:"endpoint_id"`
	Principal  *OrderBy `json:"principal"`
}

// aggregate var_pop on columns
type EndpointsVarPopFields struct {
	EndpointID *float64 `json:"endpoint_id"`
	Principal  *float64 `json:"principal"`
}

// order by var_pop() on columns of table "endpoints"
type EndpointsVarPopOrderBy struct {
	EndpointID *OrderBy `json:"endpoint_id"`
	Principal  *OrderBy `json:"principal"`
}

// aggregate var_samp on columns
type EndpointsVarSampFields struct {
	EndpointID *float64 `json:"endpoint_id"`
	Principal  *float64 `json:"principal"`
}

// order by var_samp() on columns of table "endpoints"
type EndpointsVarSampOrderBy struct {
	EndpointID *OrderBy `json:"endpoint_id"`
	Principal  *OrderBy `json:"principal"`
}

// aggregate variance on columns
type EndpointsVarianceFields struct {
	EndpointID *float64 `json:"endpoint_id"`
	Principal  *float64 `json:"principal"`
}

// order by variance() on columns of table "endpoints"
type EndpointsVarianceOrderBy struct {
	EndpointID *OrderBy `json:"endpoint_id"`
	Principal  *OrderBy `json:"principal"`
}

// aggregated selection of "file_history"
type FileHistoryAggregate struct {
	Aggregate *FileHistoryAggregateFields `json:"aggregate"`
	Nodes     []*FileHistory              `json:"nodes"`
}

// aggregate fields of "file_history"
type FileHistoryAggregateFields struct {
	Avg        *FileHistoryAvgFields        `json:"avg"`
	Count      *int                         `json:"count"`
	Max        *FileHistoryMaxFields        `json:"max"`
	Min        *FileHistoryMinFields        `json:"min"`
	Stddev     *FileHistoryStddevFields     `json:"stddev"`
	StddevPop  *FileHistoryStddevPopFields  `json:"stddev_pop"`
	StddevSamp *FileHistoryStddevSampFields `json:"stddev_samp"`
	Sum        *FileHistorySumFields        `json:"sum"`
	VarPop     *FileHistoryVarPopFields     `json:"var_pop"`
	VarSamp    *FileHistoryVarSampFields    `json:"var_samp"`
	Variance   *FileHistoryVarianceFields   `json:"variance"`
}

// order by aggregate values of table "file_history"
type FileHistoryAggregateOrderBy struct {
	Avg        *FileHistoryAvgOrderBy        `json:"avg"`
	Count      *OrderBy                      `json:"count"`
	Max        *FileHistoryMaxOrderBy        `json:"max"`
	Min        *FileHistoryMinOrderBy        `json:"min"`
	Stddev     *FileHistoryStddevOrderBy     `json:"stddev"`
	StddevPop  *FileHistoryStddevPopOrderBy  `json:"stddev_pop"`
	StddevSamp *FileHistoryStddevSampOrderBy `json:"stddev_samp"`
	Sum        *FileHistorySumOrderBy        `json:"sum"`
	VarPop     *FileHistoryVarPopOrderBy     `json:"var_pop"`
	VarSamp    *FileHistoryVarSampOrderBy    `json:"var_samp"`
	Variance   *FileHistoryVarianceOrderBy   `json:"variance"`
}

// input type for inserting array relation for remote table "file_history"
type FileHistoryArrRelInsertInput struct {
	Data       []*FileHistoryInsertInput `json:"data"`
	OnConflict *FileHistoryOnConflict    `json:"on_conflict"`
}

// aggregate avg on columns
type FileHistoryAvgFields struct {
	FileHistoryID *float64 `json:"file_history_id"`
	PrevID        *float64 `json:"prev_id"`
	ScanID        *float64 `json:"scan_id"`
}

// order by avg() on columns of table "file_history"
type FileHistoryAvgOrderBy struct {
	FileHistoryID *OrderBy `json:"file_history_id"`
	PrevID        *OrderBy `json:"prev_id"`
	ScanID        *OrderBy `json:"scan_id"`
}

// Boolean expression to filter rows from the table "file_history". All fields are combined with a logical 'AND'.
type FileHistoryBoolExp struct {
	_and          []*FileHistoryBoolExp     `json:"_and"`
	_not          *FileHistoryBoolExp       `json:"_not"`
	_or           []*FileHistoryBoolExp     `json:"_or"`
	Action        *TextComparisonExp        `json:"action"`
	ActionTstamp  *TimestamptzComparisonExp `json:"action_tstamp"`
	FileHistoryID *BigintComparisonExp      `json:"file_history_id"`
	Filename      *TextComparisonExp        `json:"filename"`
	Prev          *FileHistoryBoolExp       `json:"prev"`
	PrevID        *IntegerComparisonExp     `json:"prev_id"`
	RuleResults   *RuleResultsBoolExp       `json:"rule_results"`
	Scan          *ScansBoolExp             `json:"scan"`
	ScanID        *IntegerComparisonExp     `json:"scan_id"`
}

// input type for incrementing integer columne in table "file_history"
type FileHistoryIncInput struct {
	FileHistoryID *int64 `json:"file_history_id"`
	PrevID        *int   `json:"prev_id"`
	ScanID        *int   `json:"scan_id"`
}

// input type for inserting data into table "file_history"
type FileHistoryInsertInput struct {
	Action        *string                       `json:"action"`
	ActionTstamp  *time.Time                    `json:"action_tstamp"`
	FileHistoryID *int64                        `json:"file_history_id"`
	Filename      *string                       `json:"filename"`
	Prev          *FileHistoryObjRelInsertInput `json:"prev"`
	PrevID        *int                          `json:"prev_id"`
	RuleResults   *RuleResultsArrRelInsertInput `json:"rule_results"`
	Scan          *ScansObjRelInsertInput       `json:"scan"`
	ScanID        *int                          `json:"scan_id"`
}

// aggregate max on columns
type FileHistoryMaxFields struct {
	Action        *string    `json:"action"`
	ActionTstamp  *time.Time `json:"action_tstamp"`
	FileHistoryID *int64     `json:"file_history_id"`
	Filename      *string    `json:"filename"`
	PrevID        *int       `json:"prev_id"`
	ScanID        *int       `json:"scan_id"`
}

// order by max() on columns of table "file_history"
type FileHistoryMaxOrderBy struct {
	Action        *OrderBy `json:"action"`
	ActionTstamp  *OrderBy `json:"action_tstamp"`
	FileHistoryID *OrderBy `json:"file_history_id"`
	Filename      *OrderBy `json:"filename"`
	PrevID        *OrderBy `json:"prev_id"`
	ScanID        *OrderBy `json:"scan_id"`
}

// aggregate min on columns
type FileHistoryMinFields struct {
	Action        *string    `json:"action"`
	ActionTstamp  *time.Time `json:"action_tstamp"`
	FileHistoryID *int64     `json:"file_history_id"`
	Filename      *string    `json:"filename"`
	PrevID        *int       `json:"prev_id"`
	ScanID        *int       `json:"scan_id"`
}

// order by min() on columns of table "file_history"
type FileHistoryMinOrderBy struct {
	Action        *OrderBy `json:"action"`
	ActionTstamp  *OrderBy `json:"action_tstamp"`
	FileHistoryID *OrderBy `json:"file_history_id"`
	Filename      *OrderBy `json:"filename"`
	PrevID        *OrderBy `json:"prev_id"`
	ScanID        *OrderBy `json:"scan_id"`
}

// response of any mutation on the table "file_history"
type FileHistoryMutationResponse struct {
	// number of affected rows by the mutation
	AffectedRows int `json:"affected_rows"`
	// data of the affected rows by the mutation
	Returning []*FileHistory `json:"returning"`
}

// input type for inserting object relation for remote table "file_history"
type FileHistoryObjRelInsertInput struct {
	Data       *FileHistoryInsertInput `json:"data"`
	OnConflict *FileHistoryOnConflict  `json:"on_conflict"`
}

// on conflict condition type for table "file_history"
type FileHistoryOnConflict struct {
	Constraint    FileHistoryConstraint     `json:"constraint"`
	UpdateColumns []FileHistoryUpdateColumn `json:"update_columns"`
}

// ordering options when selecting data from "file_history"
type FileHistoryOrderBy struct {
	Action               *OrderBy                     `json:"action"`
	ActionTstamp         *OrderBy                     `json:"action_tstamp"`
	FileHistoryID        *OrderBy                     `json:"file_history_id"`
	Filename             *OrderBy                     `json:"filename"`
	Prev                 *FileHistoryOrderBy          `json:"prev"`
	PrevID               *OrderBy                     `json:"prev_id"`
	RuleResultsAggregate *RuleResultsAggregateOrderBy `json:"rule_results_aggregate"`
	Scan                 *ScansOrderBy                `json:"scan"`
	ScanID               *OrderBy                     `json:"scan_id"`
}

// input type for updating data in table "file_history"
type FileHistorySetInput struct {
	Action        *string    `json:"action"`
	ActionTstamp  *time.Time `json:"action_tstamp"`
	FileHistoryID *int64     `json:"file_history_id"`
	Filename      *string    `json:"filename"`
	PrevID        *int       `json:"prev_id"`
	ScanID        *int       `json:"scan_id"`
}

// aggregate stddev on columns
type FileHistoryStddevFields struct {
	FileHistoryID *float64 `json:"file_history_id"`
	PrevID        *float64 `json:"prev_id"`
	ScanID        *float64 `json:"scan_id"`
}

// order by stddev() on columns of table "file_history"
type FileHistoryStddevOrderBy struct {
	FileHistoryID *OrderBy `json:"file_history_id"`
	PrevID        *OrderBy `json:"prev_id"`
	ScanID        *OrderBy `json:"scan_id"`
}

// aggregate stddev_pop on columns
type FileHistoryStddevPopFields struct {
	FileHistoryID *float64 `json:"file_history_id"`
	PrevID        *float64 `json:"prev_id"`
	ScanID        *float64 `json:"scan_id"`
}

// order by stddev_pop() on columns of table "file_history"
type FileHistoryStddevPopOrderBy struct {
	FileHistoryID *OrderBy `json:"file_history_id"`
	PrevID        *OrderBy `json:"prev_id"`
	ScanID        *OrderBy `json:"scan_id"`
}

// aggregate stddev_samp on columns
type FileHistoryStddevSampFields struct {
	FileHistoryID *float64 `json:"file_history_id"`
	PrevID        *float64 `json:"prev_id"`
	ScanID        *float64 `json:"scan_id"`
}

// order by stddev_samp() on columns of table "file_history"
type FileHistoryStddevSampOrderBy struct {
	FileHistoryID *OrderBy `json:"file_history_id"`
	PrevID        *OrderBy `json:"prev_id"`
	ScanID        *OrderBy `json:"scan_id"`
}

// aggregate sum on columns
type FileHistorySumFields struct {
	FileHistoryID *int64 `json:"file_history_id"`
	PrevID        *int   `json:"prev_id"`
	ScanID        *int   `json:"scan_id"`
}

// order by sum() on columns of table "file_history"
type FileHistorySumOrderBy struct {
	FileHistoryID *OrderBy `json:"file_history_id"`
	PrevID        *OrderBy `json:"prev_id"`
	ScanID        *OrderBy `json:"scan_id"`
}

// aggregate var_pop on columns
type FileHistoryVarPopFields struct {
	FileHistoryID *float64 `json:"file_history_id"`
	PrevID        *float64 `json:"prev_id"`
	ScanID        *float64 `json:"scan_id"`
}

// order by var_pop() on columns of table "file_history"
type FileHistoryVarPopOrderBy struct {
	FileHistoryID *OrderBy `json:"file_history_id"`
	PrevID        *OrderBy `json:"prev_id"`
	ScanID        *OrderBy `json:"scan_id"`
}

// aggregate var_samp on columns
type FileHistoryVarSampFields struct {
	FileHistoryID *float64 `json:"file_history_id"`
	PrevID        *float64 `json:"prev_id"`
	ScanID        *float64 `json:"scan_id"`
}

// order by var_samp() on columns of table "file_history"
type FileHistoryVarSampOrderBy struct {
	FileHistoryID *OrderBy `json:"file_history_id"`
	PrevID        *OrderBy `json:"prev_id"`
	ScanID        *OrderBy `json:"scan_id"`
}

// aggregate variance on columns
type FileHistoryVarianceFields struct {
	FileHistoryID *float64 `json:"file_history_id"`
	PrevID        *float64 `json:"prev_id"`
	ScanID        *float64 `json:"scan_id"`
}

// order by variance() on columns of table "file_history"
type FileHistoryVarianceOrderBy struct {
	FileHistoryID *OrderBy `json:"file_history_id"`
	PrevID        *OrderBy `json:"prev_id"`
	ScanID        *OrderBy `json:"scan_id"`
}

// columns and relationships of "files"
type Files struct {
	// An object relationship
	FileHistory   *FileHistory `json:"file_history"`
	FileHistoryID *int64       `json:"file_history_id"`
	// An array relationship
	RuleResults []*RuleResults `json:"rule_results"`
	// An aggregated array relationship
	RuleResultsAggregate *RuleResultsAggregate `json:"rule_results_aggregate"`
}

// aggregated selection of "files"
type FilesAggregate struct {
	Aggregate *FilesAggregateFields `json:"aggregate"`
	Nodes     []*Files              `json:"nodes"`
}

// aggregate fields of "files"
type FilesAggregateFields struct {
	Avg        *FilesAvgFields        `json:"avg"`
	Count      *int                   `json:"count"`
	Max        *FilesMaxFields        `json:"max"`
	Min        *FilesMinFields        `json:"min"`
	Stddev     *FilesStddevFields     `json:"stddev"`
	StddevPop  *FilesStddevPopFields  `json:"stddev_pop"`
	StddevSamp *FilesStddevSampFields `json:"stddev_samp"`
	Sum        *FilesSumFields        `json:"sum"`
	VarPop     *FilesVarPopFields     `json:"var_pop"`
	VarSamp    *FilesVarSampFields    `json:"var_samp"`
	Variance   *FilesVarianceFields   `json:"variance"`
}

// order by aggregate values of table "files"
type FilesAggregateOrderBy struct {
	Avg        *FilesAvgOrderBy        `json:"avg"`
	Count      *OrderBy                `json:"count"`
	Max        *FilesMaxOrderBy        `json:"max"`
	Min        *FilesMinOrderBy        `json:"min"`
	Stddev     *FilesStddevOrderBy     `json:"stddev"`
	StddevPop  *FilesStddevPopOrderBy  `json:"stddev_pop"`
	StddevSamp *FilesStddevSampOrderBy `json:"stddev_samp"`
	Sum        *FilesSumOrderBy        `json:"sum"`
	VarPop     *FilesVarPopOrderBy     `json:"var_pop"`
	VarSamp    *FilesVarSampOrderBy    `json:"var_samp"`
	Variance   *FilesVarianceOrderBy   `json:"variance"`
}

// aggregate avg on columns
type FilesAvgFields struct {
	FileHistoryID *float64 `json:"file_history_id"`
}

// order by avg() on columns of table "files"
type FilesAvgOrderBy struct {
	FileHistoryID *OrderBy `json:"file_history_id"`
}

// Boolean expression to filter rows from the table "files". All fields are combined with a logical 'AND'.
type FilesBoolExp struct {
	_and          []*FilesBoolExp      `json:"_and"`
	_not          *FilesBoolExp        `json:"_not"`
	_or           []*FilesBoolExp      `json:"_or"`
	FileHistory   *FileHistoryBoolExp  `json:"file_history"`
	FileHistoryID *BigintComparisonExp `json:"file_history_id"`
	RuleResults   *RuleResultsBoolExp  `json:"rule_results"`
}

// aggregate max on columns
type FilesMaxFields struct {
	FileHistoryID *int64 `json:"file_history_id"`
}

// order by max() on columns of table "files"
type FilesMaxOrderBy struct {
	FileHistoryID *OrderBy `json:"file_history_id"`
}

// aggregate min on columns
type FilesMinFields struct {
	FileHistoryID *int64 `json:"file_history_id"`
}

// order by min() on columns of table "files"
type FilesMinOrderBy struct {
	FileHistoryID *OrderBy `json:"file_history_id"`
}

// ordering options when selecting data from "files"
type FilesOrderBy struct {
	FileHistory          *FileHistoryOrderBy          `json:"file_history"`
	FileHistoryID        *OrderBy                     `json:"file_history_id"`
	RuleResultsAggregate *RuleResultsAggregateOrderBy `json:"rule_results_aggregate"`
}

// aggregate stddev on columns
type FilesStddevFields struct {
	FileHistoryID *float64 `json:"file_history_id"`
}

// order by stddev() on columns of table "files"
type FilesStddevOrderBy struct {
	FileHistoryID *OrderBy `json:"file_history_id"`
}

// aggregate stddev_pop on columns
type FilesStddevPopFields struct {
	FileHistoryID *float64 `json:"file_history_id"`
}

// order by stddev_pop() on columns of table "files"
type FilesStddevPopOrderBy struct {
	FileHistoryID *OrderBy `json:"file_history_id"`
}

// aggregate stddev_samp on columns
type FilesStddevSampFields struct {
	FileHistoryID *float64 `json:"file_history_id"`
}

// order by stddev_samp() on columns of table "files"
type FilesStddevSampOrderBy struct {
	FileHistoryID *OrderBy `json:"file_history_id"`
}

// aggregate sum on columns
type FilesSumFields struct {
	FileHistoryID *int64 `json:"file_history_id"`
}

// order by sum() on columns of table "files"
type FilesSumOrderBy struct {
	FileHistoryID *OrderBy `json:"file_history_id"`
}

// aggregate var_pop on columns
type FilesVarPopFields struct {
	FileHistoryID *float64 `json:"file_history_id"`
}

// order by var_pop() on columns of table "files"
type FilesVarPopOrderBy struct {
	FileHistoryID *OrderBy `json:"file_history_id"`
}

// aggregate var_samp on columns
type FilesVarSampFields struct {
	FileHistoryID *float64 `json:"file_history_id"`
}

// order by var_samp() on columns of table "files"
type FilesVarSampOrderBy struct {
	FileHistoryID *OrderBy `json:"file_history_id"`
}

// aggregate variance on columns
type FilesVarianceFields struct {
	FileHistoryID *float64 `json:"file_history_id"`
}

// order by variance() on columns of table "files"
type FilesVarianceOrderBy struct {
	FileHistoryID *OrderBy `json:"file_history_id"`
}

// expression to compare columns of type integer. All fields are combined with logical 'AND'.
type IntegerComparisonExp struct {
	_eq     *int   `json:"_eq"`
	_gt     *int   `json:"_gt"`
	_gte    *int   `json:"_gte"`
	_in     []*int `json:"_in"`
	_isNull *bool  `json:"_is_null"`
	_lt     *int   `json:"_lt"`
	_lte    *int   `json:"_lte"`
	_neq    *int   `json:"_neq"`
	_nin    []*int `json:"_nin"`
}

// expression to compare columns of type jsonb. All fields are combined with logical 'AND'.
type JsonbComparisonExp struct {
	// is the column contained in the given json value
	_containedIn *string `json:"_contained_in"`
	// does the column contain the given json value at the top level
	_contains *string `json:"_contains"`
	_eq       *string `json:"_eq"`
	_gt       *string `json:"_gt"`
	_gte      *string `json:"_gte"`
	// does the string exist as a top-level key in the column
	_hasKey *string `json:"_has_key"`
	// do all of these strings exist as top-level keys in the column
	_hasKeysAll []string `json:"_has_keys_all"`
	// do any of these strings exist as top-level keys in the column
	_hasKeysAny []string  `json:"_has_keys_any"`
	_in         []*string `json:"_in"`
	_isNull     *bool     `json:"_is_null"`
	_lt         *string   `json:"_lt"`
	_lte        *string   `json:"_lte"`
	_neq        *string   `json:"_neq"`
	_nin        []*string `json:"_nin"`
}

// aggregated selection of "rule_results"
type RuleResultsAggregate struct {
	Aggregate *RuleResultsAggregateFields `json:"aggregate"`
	Nodes     []*RuleResults              `json:"nodes"`
}

// aggregate fields of "rule_results"
type RuleResultsAggregateFields struct {
	Avg        *RuleResultsAvgFields        `json:"avg"`
	Count      *int                         `json:"count"`
	Max        *RuleResultsMaxFields        `json:"max"`
	Min        *RuleResultsMinFields        `json:"min"`
	Stddev     *RuleResultsStddevFields     `json:"stddev"`
	StddevPop  *RuleResultsStddevPopFields  `json:"stddev_pop"`
	StddevSamp *RuleResultsStddevSampFields `json:"stddev_samp"`
	Sum        *RuleResultsSumFields        `json:"sum"`
	VarPop     *RuleResultsVarPopFields     `json:"var_pop"`
	VarSamp    *RuleResultsVarSampFields    `json:"var_samp"`
	Variance   *RuleResultsVarianceFields   `json:"variance"`
}

// order by aggregate values of table "rule_results"
type RuleResultsAggregateOrderBy struct {
	Avg        *RuleResultsAvgOrderBy        `json:"avg"`
	Count      *OrderBy                      `json:"count"`
	Max        *RuleResultsMaxOrderBy        `json:"max"`
	Min        *RuleResultsMinOrderBy        `json:"min"`
	Stddev     *RuleResultsStddevOrderBy     `json:"stddev"`
	StddevPop  *RuleResultsStddevPopOrderBy  `json:"stddev_pop"`
	StddevSamp *RuleResultsStddevSampOrderBy `json:"stddev_samp"`
	Sum        *RuleResultsSumOrderBy        `json:"sum"`
	VarPop     *RuleResultsVarPopOrderBy     `json:"var_pop"`
	VarSamp    *RuleResultsVarSampOrderBy    `json:"var_samp"`
	Variance   *RuleResultsVarianceOrderBy   `json:"variance"`
}

// input type for inserting array relation for remote table "rule_results"
type RuleResultsArrRelInsertInput struct {
	Data       []*RuleResultsInsertInput `json:"data"`
	OnConflict *RuleResultsOnConflict    `json:"on_conflict"`
}

// aggregate avg on columns
type RuleResultsAvgFields struct {
	FileHistoryID *float64 `json:"file_history_id"`
	RuleID        *float64 `json:"rule_id"`
	RuleResultID  *float64 `json:"rule_result_id"`
}

// order by avg() on columns of table "rule_results"
type RuleResultsAvgOrderBy struct {
	FileHistoryID *OrderBy `json:"file_history_id"`
	RuleID        *OrderBy `json:"rule_id"`
	RuleResultID  *OrderBy `json:"rule_result_id"`
}

// Boolean expression to filter rows from the table "rule_results". All fields are combined with a logical 'AND'.
type RuleResultsBoolExp struct {
	_and          []*RuleResultsBoolExp     `json:"_and"`
	_not          *RuleResultsBoolExp       `json:"_not"`
	_or           []*RuleResultsBoolExp     `json:"_or"`
	CreatedAt     *TimestamptzComparisonExp `json:"created_at"`
	FileHistory   *FileHistoryBoolExp       `json:"file_history"`
	FileHistoryID *IntegerComparisonExp     `json:"file_history_id"`
	Rule          *RulesBoolExp             `json:"rule"`
	RuleID        *IntegerComparisonExp     `json:"rule_id"`
	RuleResultID  *IntegerComparisonExp     `json:"rule_result_id"`
	Tag           *TextComparisonExp        `json:"tag"`
	Value         *TextComparisonExp        `json:"value"`
}

// input type for incrementing integer columne in table "rule_results"
type RuleResultsIncInput struct {
	FileHistoryID *int `json:"file_history_id"`
	RuleID        *int `json:"rule_id"`
	RuleResultID  *int `json:"rule_result_id"`
}

// input type for inserting data into table "rule_results"
type RuleResultsInsertInput struct {
	CreatedAt     *time.Time                    `json:"created_at"`
	FileHistory   *FileHistoryObjRelInsertInput `json:"file_history"`
	FileHistoryID *int                          `json:"file_history_id"`
	Rule          *RulesObjRelInsertInput       `json:"rule"`
	RuleID        *int                          `json:"rule_id"`
	RuleResultID  *int                          `json:"rule_result_id"`
	Tag           *string                       `json:"tag"`
	Value         *string                       `json:"value"`
}

// aggregate max on columns
type RuleResultsMaxFields struct {
	CreatedAt     *time.Time `json:"created_at"`
	FileHistoryID *int       `json:"file_history_id"`
	RuleID        *int       `json:"rule_id"`
	RuleResultID  *int       `json:"rule_result_id"`
	Tag           *string    `json:"tag"`
	Value         *string    `json:"value"`
}

// order by max() on columns of table "rule_results"
type RuleResultsMaxOrderBy struct {
	CreatedAt     *OrderBy `json:"created_at"`
	FileHistoryID *OrderBy `json:"file_history_id"`
	RuleID        *OrderBy `json:"rule_id"`
	RuleResultID  *OrderBy `json:"rule_result_id"`
	Tag           *OrderBy `json:"tag"`
	Value         *OrderBy `json:"value"`
}

// aggregate min on columns
type RuleResultsMinFields struct {
	CreatedAt     *time.Time `json:"created_at"`
	FileHistoryID *int       `json:"file_history_id"`
	RuleID        *int       `json:"rule_id"`
	RuleResultID  *int       `json:"rule_result_id"`
	Tag           *string    `json:"tag"`
	Value         *string    `json:"value"`
}

// order by min() on columns of table "rule_results"
type RuleResultsMinOrderBy struct {
	CreatedAt     *OrderBy `json:"created_at"`
	FileHistoryID *OrderBy `json:"file_history_id"`
	RuleID        *OrderBy `json:"rule_id"`
	RuleResultID  *OrderBy `json:"rule_result_id"`
	Tag           *OrderBy `json:"tag"`
	Value         *OrderBy `json:"value"`
}

// response of any mutation on the table "rule_results"
type RuleResultsMutationResponse struct {
	// number of affected rows by the mutation
	AffectedRows int `json:"affected_rows"`
	// data of the affected rows by the mutation
	Returning []*RuleResults `json:"returning"`
}

// input type for inserting object relation for remote table "rule_results"
type RuleResultsObjRelInsertInput struct {
	Data       *RuleResultsInsertInput `json:"data"`
	OnConflict *RuleResultsOnConflict  `json:"on_conflict"`
}

// on conflict condition type for table "rule_results"
type RuleResultsOnConflict struct {
	Constraint    RuleResultsConstraint     `json:"constraint"`
	UpdateColumns []RuleResultsUpdateColumn `json:"update_columns"`
}

// ordering options when selecting data from "rule_results"
type RuleResultsOrderBy struct {
	CreatedAt     *OrderBy            `json:"created_at"`
	FileHistory   *FileHistoryOrderBy `json:"file_history"`
	FileHistoryID *OrderBy            `json:"file_history_id"`
	Rule          *RulesOrderBy       `json:"rule"`
	RuleID        *OrderBy            `json:"rule_id"`
	RuleResultID  *OrderBy            `json:"rule_result_id"`
	Tag           *OrderBy            `json:"tag"`
	Value         *OrderBy            `json:"value"`
}

// input type for updating data in table "rule_results"
type RuleResultsSetInput struct {
	CreatedAt     *time.Time `json:"created_at"`
	FileHistoryID *int       `json:"file_history_id"`
	RuleID        *int       `json:"rule_id"`
	RuleResultID  *int       `json:"rule_result_id"`
	Tag           *string    `json:"tag"`
	Value         *string    `json:"value"`
}

// aggregate stddev on columns
type RuleResultsStddevFields struct {
	FileHistoryID *float64 `json:"file_history_id"`
	RuleID        *float64 `json:"rule_id"`
	RuleResultID  *float64 `json:"rule_result_id"`
}

// order by stddev() on columns of table "rule_results"
type RuleResultsStddevOrderBy struct {
	FileHistoryID *OrderBy `json:"file_history_id"`
	RuleID        *OrderBy `json:"rule_id"`
	RuleResultID  *OrderBy `json:"rule_result_id"`
}

// aggregate stddev_pop on columns
type RuleResultsStddevPopFields struct {
	FileHistoryID *float64 `json:"file_history_id"`
	RuleID        *float64 `json:"rule_id"`
	RuleResultID  *float64 `json:"rule_result_id"`
}

// order by stddev_pop() on columns of table "rule_results"
type RuleResultsStddevPopOrderBy struct {
	FileHistoryID *OrderBy `json:"file_history_id"`
	RuleID        *OrderBy `json:"rule_id"`
	RuleResultID  *OrderBy `json:"rule_result_id"`
}

// aggregate stddev_samp on columns
type RuleResultsStddevSampFields struct {
	FileHistoryID *float64 `json:"file_history_id"`
	RuleID        *float64 `json:"rule_id"`
	RuleResultID  *float64 `json:"rule_result_id"`
}

// order by stddev_samp() on columns of table "rule_results"
type RuleResultsStddevSampOrderBy struct {
	FileHistoryID *OrderBy `json:"file_history_id"`
	RuleID        *OrderBy `json:"rule_id"`
	RuleResultID  *OrderBy `json:"rule_result_id"`
}

// aggregate sum on columns
type RuleResultsSumFields struct {
	FileHistoryID *int `json:"file_history_id"`
	RuleID        *int `json:"rule_id"`
	RuleResultID  *int `json:"rule_result_id"`
}

// order by sum() on columns of table "rule_results"
type RuleResultsSumOrderBy struct {
	FileHistoryID *OrderBy `json:"file_history_id"`
	RuleID        *OrderBy `json:"rule_id"`
	RuleResultID  *OrderBy `json:"rule_result_id"`
}

// aggregate var_pop on columns
type RuleResultsVarPopFields struct {
	FileHistoryID *float64 `json:"file_history_id"`
	RuleID        *float64 `json:"rule_id"`
	RuleResultID  *float64 `json:"rule_result_id"`
}

// order by var_pop() on columns of table "rule_results"
type RuleResultsVarPopOrderBy struct {
	FileHistoryID *OrderBy `json:"file_history_id"`
	RuleID        *OrderBy `json:"rule_id"`
	RuleResultID  *OrderBy `json:"rule_result_id"`
}

// aggregate var_samp on columns
type RuleResultsVarSampFields struct {
	FileHistoryID *float64 `json:"file_history_id"`
	RuleID        *float64 `json:"rule_id"`
	RuleResultID  *float64 `json:"rule_result_id"`
}

// order by var_samp() on columns of table "rule_results"
type RuleResultsVarSampOrderBy struct {
	FileHistoryID *OrderBy `json:"file_history_id"`
	RuleID        *OrderBy `json:"rule_id"`
	RuleResultID  *OrderBy `json:"rule_result_id"`
}

// aggregate variance on columns
type RuleResultsVarianceFields struct {
	FileHistoryID *float64 `json:"file_history_id"`
	RuleID        *float64 `json:"rule_id"`
	RuleResultID  *float64 `json:"rule_result_id"`
}

// order by variance() on columns of table "rule_results"
type RuleResultsVarianceOrderBy struct {
	FileHistoryID *OrderBy `json:"file_history_id"`
	RuleID        *OrderBy `json:"rule_id"`
	RuleResultID  *OrderBy `json:"rule_result_id"`
}

// columns and relationships of "rules"
type Rules struct {
	Ignore    bool   `json:"ignore"`
	Principal *int   `json:"principal"`
	Priority  int    `json:"priority"`
	Rule      string `json:"rule"`
	RuleID    int    `json:"rule_id"`
	// An array relationship
	RuleResults []*RuleResults `json:"rule_results"`
	// An aggregated array relationship
	RuleResultsAggregate *RuleResultsAggregate `json:"rule_results_aggregate"`
	RuleType             string                `json:"rule_type"`
}

// aggregated selection of "rules"
type RulesAggregate struct {
	Aggregate *RulesAggregateFields `json:"aggregate"`
	Nodes     []*Rules              `json:"nodes"`
}

// aggregate fields of "rules"
type RulesAggregateFields struct {
	Avg        *RulesAvgFields        `json:"avg"`
	Count      *int                   `json:"count"`
	Max        *RulesMaxFields        `json:"max"`
	Min        *RulesMinFields        `json:"min"`
	Stddev     *RulesStddevFields     `json:"stddev"`
	StddevPop  *RulesStddevPopFields  `json:"stddev_pop"`
	StddevSamp *RulesStddevSampFields `json:"stddev_samp"`
	Sum        *RulesSumFields        `json:"sum"`
	VarPop     *RulesVarPopFields     `json:"var_pop"`
	VarSamp    *RulesVarSampFields    `json:"var_samp"`
	Variance   *RulesVarianceFields   `json:"variance"`
}

// order by aggregate values of table "rules"
type RulesAggregateOrderBy struct {
	Avg        *RulesAvgOrderBy        `json:"avg"`
	Count      *OrderBy                `json:"count"`
	Max        *RulesMaxOrderBy        `json:"max"`
	Min        *RulesMinOrderBy        `json:"min"`
	Stddev     *RulesStddevOrderBy     `json:"stddev"`
	StddevPop  *RulesStddevPopOrderBy  `json:"stddev_pop"`
	StddevSamp *RulesStddevSampOrderBy `json:"stddev_samp"`
	Sum        *RulesSumOrderBy        `json:"sum"`
	VarPop     *RulesVarPopOrderBy     `json:"var_pop"`
	VarSamp    *RulesVarSampOrderBy    `json:"var_samp"`
	Variance   *RulesVarianceOrderBy   `json:"variance"`
}

// input type for inserting array relation for remote table "rules"
type RulesArrRelInsertInput struct {
	Data       []*RulesInsertInput `json:"data"`
	OnConflict *RulesOnConflict    `json:"on_conflict"`
}

// aggregate avg on columns
type RulesAvgFields struct {
	Principal *float64 `json:"principal"`
	Priority  *float64 `json:"priority"`
	RuleID    *float64 `json:"rule_id"`
}

// order by avg() on columns of table "rules"
type RulesAvgOrderBy struct {
	Principal *OrderBy `json:"principal"`
	Priority  *OrderBy `json:"priority"`
	RuleID    *OrderBy `json:"rule_id"`
}

// Boolean expression to filter rows from the table "rules". All fields are combined with a logical 'AND'.
type RulesBoolExp struct {
	_and        []*RulesBoolExp       `json:"_and"`
	_not        *RulesBoolExp         `json:"_not"`
	_or         []*RulesBoolExp       `json:"_or"`
	Ignore      *BooleanComparisonExp `json:"ignore"`
	Principal   *IntegerComparisonExp `json:"principal"`
	Priority    *IntegerComparisonExp `json:"priority"`
	Rule        *TextComparisonExp    `json:"rule"`
	RuleID      *IntegerComparisonExp `json:"rule_id"`
	RuleResults *RuleResultsBoolExp   `json:"rule_results"`
	RuleType    *TextComparisonExp    `json:"rule_type"`
}

// input type for incrementing integer columne in table "rules"
type RulesIncInput struct {
	Principal *int `json:"principal"`
	Priority  *int `json:"priority"`
	RuleID    *int `json:"rule_id"`
}

// input type for inserting data into table "rules"
type RulesInsertInput struct {
	Ignore      *bool                         `json:"ignore"`
	Principal   *int                          `json:"principal"`
	Priority    *int                          `json:"priority"`
	Rule        *string                       `json:"rule"`
	RuleID      *int                          `json:"rule_id"`
	RuleResults *RuleResultsArrRelInsertInput `json:"rule_results"`
	RuleType    *string                       `json:"rule_type"`
}

// aggregate max on columns
type RulesMaxFields struct {
	Principal *int    `json:"principal"`
	Priority  *int    `json:"priority"`
	Rule      *string `json:"rule"`
	RuleID    *int    `json:"rule_id"`
	RuleType  *string `json:"rule_type"`
}

// order by max() on columns of table "rules"
type RulesMaxOrderBy struct {
	Principal *OrderBy `json:"principal"`
	Priority  *OrderBy `json:"priority"`
	Rule      *OrderBy `json:"rule"`
	RuleID    *OrderBy `json:"rule_id"`
	RuleType  *OrderBy `json:"rule_type"`
}

// aggregate min on columns
type RulesMinFields struct {
	Principal *int    `json:"principal"`
	Priority  *int    `json:"priority"`
	Rule      *string `json:"rule"`
	RuleID    *int    `json:"rule_id"`
	RuleType  *string `json:"rule_type"`
}

// order by min() on columns of table "rules"
type RulesMinOrderBy struct {
	Principal *OrderBy `json:"principal"`
	Priority  *OrderBy `json:"priority"`
	Rule      *OrderBy `json:"rule"`
	RuleID    *OrderBy `json:"rule_id"`
	RuleType  *OrderBy `json:"rule_type"`
}

// response of any mutation on the table "rules"
type RulesMutationResponse struct {
	// number of affected rows by the mutation
	AffectedRows int `json:"affected_rows"`
	// data of the affected rows by the mutation
	Returning []*Rules `json:"returning"`
}

// input type for inserting object relation for remote table "rules"
type RulesObjRelInsertInput struct {
	Data       *RulesInsertInput `json:"data"`
	OnConflict *RulesOnConflict  `json:"on_conflict"`
}

// on conflict condition type for table "rules"
type RulesOnConflict struct {
	Constraint    RulesConstraint     `json:"constraint"`
	UpdateColumns []RulesUpdateColumn `json:"update_columns"`
}

// ordering options when selecting data from "rules"
type RulesOrderBy struct {
	Ignore               *OrderBy                     `json:"ignore"`
	Principal            *OrderBy                     `json:"principal"`
	Priority             *OrderBy                     `json:"priority"`
	Rule                 *OrderBy                     `json:"rule"`
	RuleID               *OrderBy                     `json:"rule_id"`
	RuleResultsAggregate *RuleResultsAggregateOrderBy `json:"rule_results_aggregate"`
	RuleType             *OrderBy                     `json:"rule_type"`
}

// input type for updating data in table "rules"
type RulesSetInput struct {
	Ignore    *bool   `json:"ignore"`
	Principal *int    `json:"principal"`
	Priority  *int    `json:"priority"`
	Rule      *string `json:"rule"`
	RuleID    *int    `json:"rule_id"`
	RuleType  *string `json:"rule_type"`
}

// aggregate stddev on columns
type RulesStddevFields struct {
	Principal *float64 `json:"principal"`
	Priority  *float64 `json:"priority"`
	RuleID    *float64 `json:"rule_id"`
}

// order by stddev() on columns of table "rules"
type RulesStddevOrderBy struct {
	Principal *OrderBy `json:"principal"`
	Priority  *OrderBy `json:"priority"`
	RuleID    *OrderBy `json:"rule_id"`
}

// aggregate stddev_pop on columns
type RulesStddevPopFields struct {
	Principal *float64 `json:"principal"`
	Priority  *float64 `json:"priority"`
	RuleID    *float64 `json:"rule_id"`
}

// order by stddev_pop() on columns of table "rules"
type RulesStddevPopOrderBy struct {
	Principal *OrderBy `json:"principal"`
	Priority  *OrderBy `json:"priority"`
	RuleID    *OrderBy `json:"rule_id"`
}

// aggregate stddev_samp on columns
type RulesStddevSampFields struct {
	Principal *float64 `json:"principal"`
	Priority  *float64 `json:"priority"`
	RuleID    *float64 `json:"rule_id"`
}

// order by stddev_samp() on columns of table "rules"
type RulesStddevSampOrderBy struct {
	Principal *OrderBy `json:"principal"`
	Priority  *OrderBy `json:"priority"`
	RuleID    *OrderBy `json:"rule_id"`
}

// aggregate sum on columns
type RulesSumFields struct {
	Principal *int `json:"principal"`
	Priority  *int `json:"priority"`
	RuleID    *int `json:"rule_id"`
}

// order by sum() on columns of table "rules"
type RulesSumOrderBy struct {
	Principal *OrderBy `json:"principal"`
	Priority  *OrderBy `json:"priority"`
	RuleID    *OrderBy `json:"rule_id"`
}

// aggregate var_pop on columns
type RulesVarPopFields struct {
	Principal *float64 `json:"principal"`
	Priority  *float64 `json:"priority"`
	RuleID    *float64 `json:"rule_id"`
}

// order by var_pop() on columns of table "rules"
type RulesVarPopOrderBy struct {
	Principal *OrderBy `json:"principal"`
	Priority  *OrderBy `json:"priority"`
	RuleID    *OrderBy `json:"rule_id"`
}

// aggregate var_samp on columns
type RulesVarSampFields struct {
	Principal *float64 `json:"principal"`
	Priority  *float64 `json:"priority"`
	RuleID    *float64 `json:"rule_id"`
}

// order by var_samp() on columns of table "rules"
type RulesVarSampOrderBy struct {
	Principal *OrderBy `json:"principal"`
	Priority  *OrderBy `json:"priority"`
	RuleID    *OrderBy `json:"rule_id"`
}

// aggregate variance on columns
type RulesVarianceFields struct {
	Principal *float64 `json:"principal"`
	Priority  *float64 `json:"priority"`
	RuleID    *float64 `json:"rule_id"`
}

// order by variance() on columns of table "rules"
type RulesVarianceOrderBy struct {
	Principal *OrderBy `json:"principal"`
	Priority  *OrderBy `json:"priority"`
	RuleID    *OrderBy `json:"rule_id"`
}

// columns and relationships of "scans"
type Scans struct {
	CompletedAt *time.Time `json:"completed_at"`
	// An array relationship
	FileHistories []*FileHistory `json:"file_histories"`
	// An aggregated array relationship
	FileHistoriesAggregate *FileHistoryAggregate `json:"file_histories_aggregate"`
	ScanID                 int                   `json:"scan_id"`
	StartedAt              time.Time             `json:"started_at"`
}

// aggregated selection of "scans"
type ScansAggregate struct {
	Aggregate *ScansAggregateFields `json:"aggregate"`
	Nodes     []*Scans              `json:"nodes"`
}

// aggregate fields of "scans"
type ScansAggregateFields struct {
	Avg        *ScansAvgFields        `json:"avg"`
	Count      *int                   `json:"count"`
	Max        *ScansMaxFields        `json:"max"`
	Min        *ScansMinFields        `json:"min"`
	Stddev     *ScansStddevFields     `json:"stddev"`
	StddevPop  *ScansStddevPopFields  `json:"stddev_pop"`
	StddevSamp *ScansStddevSampFields `json:"stddev_samp"`
	Sum        *ScansSumFields        `json:"sum"`
	VarPop     *ScansVarPopFields     `json:"var_pop"`
	VarSamp    *ScansVarSampFields    `json:"var_samp"`
	Variance   *ScansVarianceFields   `json:"variance"`
}

// order by aggregate values of table "scans"
type ScansAggregateOrderBy struct {
	Avg        *ScansAvgOrderBy        `json:"avg"`
	Count      *OrderBy                `json:"count"`
	Max        *ScansMaxOrderBy        `json:"max"`
	Min        *ScansMinOrderBy        `json:"min"`
	Stddev     *ScansStddevOrderBy     `json:"stddev"`
	StddevPop  *ScansStddevPopOrderBy  `json:"stddev_pop"`
	StddevSamp *ScansStddevSampOrderBy `json:"stddev_samp"`
	Sum        *ScansSumOrderBy        `json:"sum"`
	VarPop     *ScansVarPopOrderBy     `json:"var_pop"`
	VarSamp    *ScansVarSampOrderBy    `json:"var_samp"`
	Variance   *ScansVarianceOrderBy   `json:"variance"`
}

// input type for inserting array relation for remote table "scans"
type ScansArrRelInsertInput struct {
	Data       []*ScansInsertInput `json:"data"`
	OnConflict *ScansOnConflict    `json:"on_conflict"`
}

// aggregate avg on columns
type ScansAvgFields struct {
	ScanID *float64 `json:"scan_id"`
}

// order by avg() on columns of table "scans"
type ScansAvgOrderBy struct {
	ScanID *OrderBy `json:"scan_id"`
}

// Boolean expression to filter rows from the table "scans". All fields are combined with a logical 'AND'.
type ScansBoolExp struct {
	_and          []*ScansBoolExp           `json:"_and"`
	_not          *ScansBoolExp             `json:"_not"`
	_or           []*ScansBoolExp           `json:"_or"`
	CompletedAt   *TimestamptzComparisonExp `json:"completed_at"`
	FileHistories *FileHistoryBoolExp       `json:"file_histories"`
	ScanID        *IntegerComparisonExp     `json:"scan_id"`
	StartedAt     *TimestamptzComparisonExp `json:"started_at"`
}

// input type for incrementing integer columne in table "scans"
type ScansIncInput struct {
	ScanID *int `json:"scan_id"`
}

// input type for inserting data into table "scans"
type ScansInsertInput struct {
	CompletedAt   *time.Time                    `json:"completed_at"`
	FileHistories *FileHistoryArrRelInsertInput `json:"file_histories"`
	ScanID        *int                          `json:"scan_id"`
	StartedAt     *time.Time                    `json:"started_at"`
}

// aggregate max on columns
type ScansMaxFields struct {
	CompletedAt *time.Time `json:"completed_at"`
	ScanID      *int       `json:"scan_id"`
	StartedAt   *time.Time `json:"started_at"`
}

// order by max() on columns of table "scans"
type ScansMaxOrderBy struct {
	CompletedAt *OrderBy `json:"completed_at"`
	ScanID      *OrderBy `json:"scan_id"`
	StartedAt   *OrderBy `json:"started_at"`
}

// aggregate min on columns
type ScansMinFields struct {
	CompletedAt *time.Time `json:"completed_at"`
	ScanID      *int       `json:"scan_id"`
	StartedAt   *time.Time `json:"started_at"`
}

// order by min() on columns of table "scans"
type ScansMinOrderBy struct {
	CompletedAt *OrderBy `json:"completed_at"`
	ScanID      *OrderBy `json:"scan_id"`
	StartedAt   *OrderBy `json:"started_at"`
}

// response of any mutation on the table "scans"
type ScansMutationResponse struct {
	// number of affected rows by the mutation
	AffectedRows int `json:"affected_rows"`
	// data of the affected rows by the mutation
	Returning []*Scans `json:"returning"`
}

// input type for inserting object relation for remote table "scans"
type ScansObjRelInsertInput struct {
	Data       *ScansInsertInput `json:"data"`
	OnConflict *ScansOnConflict  `json:"on_conflict"`
}

// on conflict condition type for table "scans"
type ScansOnConflict struct {
	Constraint    ScansConstraint     `json:"constraint"`
	UpdateColumns []ScansUpdateColumn `json:"update_columns"`
}

// ordering options when selecting data from "scans"
type ScansOrderBy struct {
	CompletedAt            *OrderBy                     `json:"completed_at"`
	FileHistoriesAggregate *FileHistoryAggregateOrderBy `json:"file_histories_aggregate"`
	ScanID                 *OrderBy                     `json:"scan_id"`
	StartedAt              *OrderBy                     `json:"started_at"`
}

// input type for updating data in table "scans"
type ScansSetInput struct {
	CompletedAt *time.Time `json:"completed_at"`
	ScanID      *int       `json:"scan_id"`
	StartedAt   *time.Time `json:"started_at"`
}

// aggregate stddev on columns
type ScansStddevFields struct {
	ScanID *float64 `json:"scan_id"`
}

// order by stddev() on columns of table "scans"
type ScansStddevOrderBy struct {
	ScanID *OrderBy `json:"scan_id"`
}

// aggregate stddev_pop on columns
type ScansStddevPopFields struct {
	ScanID *float64 `json:"scan_id"`
}

// order by stddev_pop() on columns of table "scans"
type ScansStddevPopOrderBy struct {
	ScanID *OrderBy `json:"scan_id"`
}

// aggregate stddev_samp on columns
type ScansStddevSampFields struct {
	ScanID *float64 `json:"scan_id"`
}

// order by stddev_samp() on columns of table "scans"
type ScansStddevSampOrderBy struct {
	ScanID *OrderBy `json:"scan_id"`
}

// aggregate sum on columns
type ScansSumFields struct {
	ScanID *int `json:"scan_id"`
}

// order by sum() on columns of table "scans"
type ScansSumOrderBy struct {
	ScanID *OrderBy `json:"scan_id"`
}

// aggregate var_pop on columns
type ScansVarPopFields struct {
	ScanID *float64 `json:"scan_id"`
}

// order by var_pop() on columns of table "scans"
type ScansVarPopOrderBy struct {
	ScanID *OrderBy `json:"scan_id"`
}

// aggregate var_samp on columns
type ScansVarSampFields struct {
	ScanID *float64 `json:"scan_id"`
}

// order by var_samp() on columns of table "scans"
type ScansVarSampOrderBy struct {
	ScanID *OrderBy `json:"scan_id"`
}

// aggregate variance on columns
type ScansVarianceFields struct {
	ScanID *float64 `json:"scan_id"`
}

// order by variance() on columns of table "scans"
type ScansVarianceOrderBy struct {
	ScanID *OrderBy `json:"scan_id"`
}

// expression to compare columns of type text. All fields are combined with logical 'AND'.
type TextComparisonExp struct {
	_eq       *string   `json:"_eq"`
	_gt       *string   `json:"_gt"`
	_gte      *string   `json:"_gte"`
	_ilike    *string   `json:"_ilike"`
	_in       []*string `json:"_in"`
	_isNull   *bool     `json:"_is_null"`
	_like     *string   `json:"_like"`
	_lt       *string   `json:"_lt"`
	_lte      *string   `json:"_lte"`
	_neq      *string   `json:"_neq"`
	_nilike   *string   `json:"_nilike"`
	_nin      []*string `json:"_nin"`
	_nlike    *string   `json:"_nlike"`
	_nsimilar *string   `json:"_nsimilar"`
	_similar  *string   `json:"_similar"`
}

// expression to compare columns of type timestamptz. All fields are combined with logical 'AND'.
type TimestamptzComparisonExp struct {
	_eq     *time.Time   `json:"_eq"`
	_gt     *time.Time   `json:"_gt"`
	_gte    *time.Time   `json:"_gte"`
	_in     []*time.Time `json:"_in"`
	_isNull *bool        `json:"_is_null"`
	_lt     *time.Time   `json:"_lt"`
	_lte    *time.Time   `json:"_lte"`
	_neq    *time.Time   `json:"_neq"`
	_nin    []*time.Time `json:"_nin"`
}

// ConflictAction
type ConflictAction string

const (
	// ignore the insert on this row
	ConflictActionIgnore ConflictAction = "ignore"
	// update the row with the given values
	ConflictActionUpdate ConflictAction = "update"
)

var AllConflictAction = []ConflictAction{
	ConflictActionIgnore,
	ConflictActionUpdate,
}

func (e ConflictAction) IsValid() bool {
	switch e {
	case ConflictActionIgnore, ConflictActionUpdate:
		return true
	}
	return false
}

func (e ConflictAction) String() string {
	return string(e)
}

func (e *ConflictAction) UnmarshalGQL(v interface{}) error {
	str, ok := v.(string)
	if !ok {
		return fmt.Errorf("enums must be strings")
	}

	*e = ConflictAction(str)
	if !e.IsValid() {
		return fmt.Errorf("%s is not a valid conflict_action", str)
	}
	return nil
}

func (e ConflictAction) MarshalGQL(w io.Writer) {
	fmt.Fprint(w, strconv.Quote(e.String()))
}

// UniqueOrPrimaryKeyConstraintsOnTable"domainUsers"
type DomainUsersConstraint string

const (
	// unique or primary key constraint
	DomainUsersConstraintDomainUsersPkey DomainUsersConstraint = "domainUsers_pkey"
	// unique or primary key constraint
	DomainUsersConstraintDomainUsersUsernameKey DomainUsersConstraint = "domainUsers_username_key"
)

var AllDomainUsersConstraint = []DomainUsersConstraint{
	DomainUsersConstraintDomainUsersPkey,
	DomainUsersConstraintDomainUsersUsernameKey,
}

func (e DomainUsersConstraint) IsValid() bool {
	switch e {
	case DomainUsersConstraintDomainUsersPkey, DomainUsersConstraintDomainUsersUsernameKey:
		return true
	}
	return false
}

func (e DomainUsersConstraint) String() string {
	return string(e)
}

func (e *DomainUsersConstraint) UnmarshalGQL(v interface{}) error {
	str, ok := v.(string)
	if !ok {
		return fmt.Errorf("enums must be strings")
	}

	*e = DomainUsersConstraint(str)
	if !e.IsValid() {
		return fmt.Errorf("%s is not a valid domain_users_constraint", str)
	}
	return nil
}

func (e DomainUsersConstraint) MarshalGQL(w io.Writer) {
	fmt.Fprint(w, strconv.Quote(e.String()))
}

// SelectColumnsOfTable"domainUsers"
type DomainUsersSelectColumn string

const (
	// column name
	DomainUsersSelectColumnGroups DomainUsersSelectColumn = "groups"
	// column name
	DomainUsersSelectColumnName DomainUsersSelectColumn = "name"
	// column name
	DomainUsersSelectColumnSid DomainUsersSelectColumn = "sid"
	// column name
	DomainUsersSelectColumnUsername DomainUsersSelectColumn = "username"
)

var AllDomainUsersSelectColumn = []DomainUsersSelectColumn{
	DomainUsersSelectColumnGroups,
	DomainUsersSelectColumnName,
	DomainUsersSelectColumnSid,
	DomainUsersSelectColumnUsername,
}

func (e DomainUsersSelectColumn) IsValid() bool {
	switch e {
	case DomainUsersSelectColumnGroups, DomainUsersSelectColumnName, DomainUsersSelectColumnSid, DomainUsersSelectColumnUsername:
		return true
	}
	return false
}

func (e DomainUsersSelectColumn) String() string {
	return string(e)
}

func (e *DomainUsersSelectColumn) UnmarshalGQL(v interface{}) error {
	str, ok := v.(string)
	if !ok {
		return fmt.Errorf("enums must be strings")
	}

	*e = DomainUsersSelectColumn(str)
	if !e.IsValid() {
		return fmt.Errorf("%s is not a valid domain_users_select_column", str)
	}
	return nil
}

func (e DomainUsersSelectColumn) MarshalGQL(w io.Writer) {
	fmt.Fprint(w, strconv.Quote(e.String()))
}

// UpdateColumnsOfTable"domainUsers"
type DomainUsersUpdateColumn string

const (
	// column name
	DomainUsersUpdateColumnGroups DomainUsersUpdateColumn = "groups"
	// column name
	DomainUsersUpdateColumnName DomainUsersUpdateColumn = "name"
	// column name
	DomainUsersUpdateColumnSid DomainUsersUpdateColumn = "sid"
	// column name
	DomainUsersUpdateColumnUsername DomainUsersUpdateColumn = "username"
)

var AllDomainUsersUpdateColumn = []DomainUsersUpdateColumn{
	DomainUsersUpdateColumnGroups,
	DomainUsersUpdateColumnName,
	DomainUsersUpdateColumnSid,
	DomainUsersUpdateColumnUsername,
}

func (e DomainUsersUpdateColumn) IsValid() bool {
	switch e {
	case DomainUsersUpdateColumnGroups, DomainUsersUpdateColumnName, DomainUsersUpdateColumnSid, DomainUsersUpdateColumnUsername:
		return true
	}
	return false
}

func (e DomainUsersUpdateColumn) String() string {
	return string(e)
}

func (e *DomainUsersUpdateColumn) UnmarshalGQL(v interface{}) error {
	str, ok := v.(string)
	if !ok {
		return fmt.Errorf("enums must be strings")
	}

	*e = DomainUsersUpdateColumn(str)
	if !e.IsValid() {
		return fmt.Errorf("%s is not a valid domain_users_update_column", str)
	}
	return nil
}

func (e DomainUsersUpdateColumn) MarshalGQL(w io.Writer) {
	fmt.Fprint(w, strconv.Quote(e.String()))
}

// UniqueOrPrimaryKeyConstraintsOnTable"endpoints"
type EndpointsConstraint string

const (
	// unique or primary key constraint
	EndpointsConstraintEndpointsPathKey EndpointsConstraint = "endpoints_path_key"
	// unique or primary key constraint
	EndpointsConstraintEndpointsPkey EndpointsConstraint = "endpoints_pkey"
)

var AllEndpointsConstraint = []EndpointsConstraint{
	EndpointsConstraintEndpointsPathKey,
	EndpointsConstraintEndpointsPkey,
}

func (e EndpointsConstraint) IsValid() bool {
	switch e {
	case EndpointsConstraintEndpointsPathKey, EndpointsConstraintEndpointsPkey:
		return true
	}
	return false
}

func (e EndpointsConstraint) String() string {
	return string(e)
}

func (e *EndpointsConstraint) UnmarshalGQL(v interface{}) error {
	str, ok := v.(string)
	if !ok {
		return fmt.Errorf("enums must be strings")
	}

	*e = EndpointsConstraint(str)
	if !e.IsValid() {
		return fmt.Errorf("%s is not a valid endpoints_constraint", str)
	}
	return nil
}

func (e EndpointsConstraint) MarshalGQL(w io.Writer) {
	fmt.Fprint(w, strconv.Quote(e.String()))
}

// SelectColumnsOfTable"endpoints"
type EndpointsSelectColumn string

const (
	// column name
	EndpointsSelectColumnEndpointID EndpointsSelectColumn = "endpoint_id"
	// column name
	EndpointsSelectColumnIgnore EndpointsSelectColumn = "ignore"
	// column name
	EndpointsSelectColumnPath EndpointsSelectColumn = "path"
	// column name
	EndpointsSelectColumnPrincipal EndpointsSelectColumn = "principal"
)

var AllEndpointsSelectColumn = []EndpointsSelectColumn{
	EndpointsSelectColumnEndpointID,
	EndpointsSelectColumnIgnore,
	EndpointsSelectColumnPath,
	EndpointsSelectColumnPrincipal,
}

func (e EndpointsSelectColumn) IsValid() bool {
	switch e {
	case EndpointsSelectColumnEndpointID, EndpointsSelectColumnIgnore, EndpointsSelectColumnPath, EndpointsSelectColumnPrincipal:
		return true
	}
	return false
}

func (e EndpointsSelectColumn) String() string {
	return string(e)
}

func (e *EndpointsSelectColumn) UnmarshalGQL(v interface{}) error {
	str, ok := v.(string)
	if !ok {
		return fmt.Errorf("enums must be strings")
	}

	*e = EndpointsSelectColumn(str)
	if !e.IsValid() {
		return fmt.Errorf("%s is not a valid endpoints_select_column", str)
	}
	return nil
}

func (e EndpointsSelectColumn) MarshalGQL(w io.Writer) {
	fmt.Fprint(w, strconv.Quote(e.String()))
}

// UpdateColumnsOfTable"endpoints"
type EndpointsUpdateColumn string

const (
	// column name
	EndpointsUpdateColumnEndpointID EndpointsUpdateColumn = "endpoint_id"
	// column name
	EndpointsUpdateColumnIgnore EndpointsUpdateColumn = "ignore"
	// column name
	EndpointsUpdateColumnPath EndpointsUpdateColumn = "path"
	// column name
	EndpointsUpdateColumnPrincipal EndpointsUpdateColumn = "principal"
)

var AllEndpointsUpdateColumn = []EndpointsUpdateColumn{
	EndpointsUpdateColumnEndpointID,
	EndpointsUpdateColumnIgnore,
	EndpointsUpdateColumnPath,
	EndpointsUpdateColumnPrincipal,
}

func (e EndpointsUpdateColumn) IsValid() bool {
	switch e {
	case EndpointsUpdateColumnEndpointID, EndpointsUpdateColumnIgnore, EndpointsUpdateColumnPath, EndpointsUpdateColumnPrincipal:
		return true
	}
	return false
}

func (e EndpointsUpdateColumn) String() string {
	return string(e)
}

func (e *EndpointsUpdateColumn) UnmarshalGQL(v interface{}) error {
	str, ok := v.(string)
	if !ok {
		return fmt.Errorf("enums must be strings")
	}

	*e = EndpointsUpdateColumn(str)
	if !e.IsValid() {
		return fmt.Errorf("%s is not a valid endpoints_update_column", str)
	}
	return nil
}

func (e EndpointsUpdateColumn) MarshalGQL(w io.Writer) {
	fmt.Fprint(w, strconv.Quote(e.String()))
}

// UniqueOrPrimaryKeyConstraintsOnTable"fileHistory"
type FileHistoryConstraint string

const (
	// unique or primary key constraint
	FileHistoryConstraintFileHistoryPkey FileHistoryConstraint = "file_history_pkey"
	// unique or primary key constraint
	FileHistoryConstraintFileHistoryScanIDFilenameKey FileHistoryConstraint = "file_history_scan_id_filename_key"
	// unique or primary key constraint
	FileHistoryConstraintFileHistoryScanIDFilenamePrevIDKey FileHistoryConstraint = "file_history_scan_id_filename_prev_id_key"
)

var AllFileHistoryConstraint = []FileHistoryConstraint{
	FileHistoryConstraintFileHistoryPkey,
	FileHistoryConstraintFileHistoryScanIDFilenameKey,
	FileHistoryConstraintFileHistoryScanIDFilenamePrevIDKey,
}

func (e FileHistoryConstraint) IsValid() bool {
	switch e {
	case FileHistoryConstraintFileHistoryPkey, FileHistoryConstraintFileHistoryScanIDFilenameKey, FileHistoryConstraintFileHistoryScanIDFilenamePrevIDKey:
		return true
	}
	return false
}

func (e FileHistoryConstraint) String() string {
	return string(e)
}

func (e *FileHistoryConstraint) UnmarshalGQL(v interface{}) error {
	str, ok := v.(string)
	if !ok {
		return fmt.Errorf("enums must be strings")
	}

	*e = FileHistoryConstraint(str)
	if !e.IsValid() {
		return fmt.Errorf("%s is not a valid file_history_constraint", str)
	}
	return nil
}

func (e FileHistoryConstraint) MarshalGQL(w io.Writer) {
	fmt.Fprint(w, strconv.Quote(e.String()))
}

// SelectColumnsOfTable"fileHistory"
type FileHistorySelectColumn string

const (
	// column name
	FileHistorySelectColumnAction FileHistorySelectColumn = "action"
	// column name
	FileHistorySelectColumnActionTstamp FileHistorySelectColumn = "action_tstamp"
	// column name
	FileHistorySelectColumnFileHistoryID FileHistorySelectColumn = "file_history_id"
	// column name
	FileHistorySelectColumnFilename FileHistorySelectColumn = "filename"
	// column name
	FileHistorySelectColumnPrevID FileHistorySelectColumn = "prev_id"
	// column name
	FileHistorySelectColumnScanID FileHistorySelectColumn = "scan_id"
)

var AllFileHistorySelectColumn = []FileHistorySelectColumn{
	FileHistorySelectColumnAction,
	FileHistorySelectColumnActionTstamp,
	FileHistorySelectColumnFileHistoryID,
	FileHistorySelectColumnFilename,
	FileHistorySelectColumnPrevID,
	FileHistorySelectColumnScanID,
}

func (e FileHistorySelectColumn) IsValid() bool {
	switch e {
	case FileHistorySelectColumnAction, FileHistorySelectColumnActionTstamp, FileHistorySelectColumnFileHistoryID, FileHistorySelectColumnFilename, FileHistorySelectColumnPrevID, FileHistorySelectColumnScanID:
		return true
	}
	return false
}

func (e FileHistorySelectColumn) String() string {
	return string(e)
}

func (e *FileHistorySelectColumn) UnmarshalGQL(v interface{}) error {
	str, ok := v.(string)
	if !ok {
		return fmt.Errorf("enums must be strings")
	}

	*e = FileHistorySelectColumn(str)
	if !e.IsValid() {
		return fmt.Errorf("%s is not a valid file_history_select_column", str)
	}
	return nil
}

func (e FileHistorySelectColumn) MarshalGQL(w io.Writer) {
	fmt.Fprint(w, strconv.Quote(e.String()))
}

// UpdateColumnsOfTable"fileHistory"
type FileHistoryUpdateColumn string

const (
	// column name
	FileHistoryUpdateColumnAction FileHistoryUpdateColumn = "action"
	// column name
	FileHistoryUpdateColumnActionTstamp FileHistoryUpdateColumn = "action_tstamp"
	// column name
	FileHistoryUpdateColumnFileHistoryID FileHistoryUpdateColumn = "file_history_id"
	// column name
	FileHistoryUpdateColumnFilename FileHistoryUpdateColumn = "filename"
	// column name
	FileHistoryUpdateColumnPrevID FileHistoryUpdateColumn = "prev_id"
	// column name
	FileHistoryUpdateColumnScanID FileHistoryUpdateColumn = "scan_id"
)

var AllFileHistoryUpdateColumn = []FileHistoryUpdateColumn{
	FileHistoryUpdateColumnAction,
	FileHistoryUpdateColumnActionTstamp,
	FileHistoryUpdateColumnFileHistoryID,
	FileHistoryUpdateColumnFilename,
	FileHistoryUpdateColumnPrevID,
	FileHistoryUpdateColumnScanID,
}

func (e FileHistoryUpdateColumn) IsValid() bool {
	switch e {
	case FileHistoryUpdateColumnAction, FileHistoryUpdateColumnActionTstamp, FileHistoryUpdateColumnFileHistoryID, FileHistoryUpdateColumnFilename, FileHistoryUpdateColumnPrevID, FileHistoryUpdateColumnScanID:
		return true
	}
	return false
}

func (e FileHistoryUpdateColumn) String() string {
	return string(e)
}

func (e *FileHistoryUpdateColumn) UnmarshalGQL(v interface{}) error {
	str, ok := v.(string)
	if !ok {
		return fmt.Errorf("enums must be strings")
	}

	*e = FileHistoryUpdateColumn(str)
	if !e.IsValid() {
		return fmt.Errorf("%s is not a valid file_history_update_column", str)
	}
	return nil
}

func (e FileHistoryUpdateColumn) MarshalGQL(w io.Writer) {
	fmt.Fprint(w, strconv.Quote(e.String()))
}

// SelectColumnsOfTable"files"
type FilesSelectColumn string

const (
	// column name
	FilesSelectColumnFileHistoryID FilesSelectColumn = "file_history_id"
)

var AllFilesSelectColumn = []FilesSelectColumn{
	FilesSelectColumnFileHistoryID,
}

func (e FilesSelectColumn) IsValid() bool {
	switch e {
	case FilesSelectColumnFileHistoryID:
		return true
	}
	return false
}

func (e FilesSelectColumn) String() string {
	return string(e)
}

func (e *FilesSelectColumn) UnmarshalGQL(v interface{}) error {
	str, ok := v.(string)
	if !ok {
		return fmt.Errorf("enums must be strings")
	}

	*e = FilesSelectColumn(str)
	if !e.IsValid() {
		return fmt.Errorf("%s is not a valid files_select_column", str)
	}
	return nil
}

func (e FilesSelectColumn) MarshalGQL(w io.Writer) {
	fmt.Fprint(w, strconv.Quote(e.String()))
}

// ColumnOrderingOptions
type OrderBy string

const (
	// in the ascending order, nulls last
	OrderByAsc OrderBy = "asc"
	// in the ascending order, nulls first
	OrderByAscNullsFirst OrderBy = "asc_nulls_first"
	// in the ascending order, nulls last
	OrderByAscNullsLast OrderBy = "asc_nulls_last"
	// in the descending order, nulls first
	OrderByDesc OrderBy = "desc"
	// in the descending order, nulls first
	OrderByDescNullsFirst OrderBy = "desc_nulls_first"
	// in the descending order, nulls last
	OrderByDescNullsLast OrderBy = "desc_nulls_last"
)

var AllOrderBy = []OrderBy{
	OrderByAsc,
	OrderByAscNullsFirst,
	OrderByAscNullsLast,
	OrderByDesc,
	OrderByDescNullsFirst,
	OrderByDescNullsLast,
}

func (e OrderBy) IsValid() bool {
	switch e {
	case OrderByAsc, OrderByAscNullsFirst, OrderByAscNullsLast, OrderByDesc, OrderByDescNullsFirst, OrderByDescNullsLast:
		return true
	}
	return false
}

func (e OrderBy) String() string {
	return string(e)
}

func (e *OrderBy) UnmarshalGQL(v interface{}) error {
	str, ok := v.(string)
	if !ok {
		return fmt.Errorf("enums must be strings")
	}

	*e = OrderBy(str)
	if !e.IsValid() {
		return fmt.Errorf("%s is not a valid order_by", str)
	}
	return nil
}

func (e OrderBy) MarshalGQL(w io.Writer) {
	fmt.Fprint(w, strconv.Quote(e.String()))
}

// UniqueOrPrimaryKeyConstraintsOnTable"ruleResults"
type RuleResultsConstraint string

const (
	// unique or primary key constraint
	RuleResultsConstraintRuleResultsFileHistoryIDTagKey RuleResultsConstraint = "rule_results_file_history_id_tag_key"
	// unique or primary key constraint
	RuleResultsConstraintRuleResultsPkey RuleResultsConstraint = "rule_results_pkey"
)

var AllRuleResultsConstraint = []RuleResultsConstraint{
	RuleResultsConstraintRuleResultsFileHistoryIDTagKey,
	RuleResultsConstraintRuleResultsPkey,
}

func (e RuleResultsConstraint) IsValid() bool {
	switch e {
	case RuleResultsConstraintRuleResultsFileHistoryIDTagKey, RuleResultsConstraintRuleResultsPkey:
		return true
	}
	return false
}

func (e RuleResultsConstraint) String() string {
	return string(e)
}

func (e *RuleResultsConstraint) UnmarshalGQL(v interface{}) error {
	str, ok := v.(string)
	if !ok {
		return fmt.Errorf("enums must be strings")
	}

	*e = RuleResultsConstraint(str)
	if !e.IsValid() {
		return fmt.Errorf("%s is not a valid rule_results_constraint", str)
	}
	return nil
}

func (e RuleResultsConstraint) MarshalGQL(w io.Writer) {
	fmt.Fprint(w, strconv.Quote(e.String()))
}

// SelectColumnsOfTable"ruleResults"
type RuleResultsSelectColumn string

const (
	// column name
	RuleResultsSelectColumnCreatedAt RuleResultsSelectColumn = "created_at"
	// column name
	RuleResultsSelectColumnFileHistoryID RuleResultsSelectColumn = "file_history_id"
	// column name
	RuleResultsSelectColumnRuleID RuleResultsSelectColumn = "rule_id"
	// column name
	RuleResultsSelectColumnRuleResultID RuleResultsSelectColumn = "rule_result_id"
	// column name
	RuleResultsSelectColumnTag RuleResultsSelectColumn = "tag"
	// column name
	RuleResultsSelectColumnValue RuleResultsSelectColumn = "value"
)

var AllRuleResultsSelectColumn = []RuleResultsSelectColumn{
	RuleResultsSelectColumnCreatedAt,
	RuleResultsSelectColumnFileHistoryID,
	RuleResultsSelectColumnRuleID,
	RuleResultsSelectColumnRuleResultID,
	RuleResultsSelectColumnTag,
	RuleResultsSelectColumnValue,
}

func (e RuleResultsSelectColumn) IsValid() bool {
	switch e {
	case RuleResultsSelectColumnCreatedAt, RuleResultsSelectColumnFileHistoryID, RuleResultsSelectColumnRuleID, RuleResultsSelectColumnRuleResultID, RuleResultsSelectColumnTag, RuleResultsSelectColumnValue:
		return true
	}
	return false
}

func (e RuleResultsSelectColumn) String() string {
	return string(e)
}

func (e *RuleResultsSelectColumn) UnmarshalGQL(v interface{}) error {
	str, ok := v.(string)
	if !ok {
		return fmt.Errorf("enums must be strings")
	}

	*e = RuleResultsSelectColumn(str)
	if !e.IsValid() {
		return fmt.Errorf("%s is not a valid rule_results_select_column", str)
	}
	return nil
}

func (e RuleResultsSelectColumn) MarshalGQL(w io.Writer) {
	fmt.Fprint(w, strconv.Quote(e.String()))
}

// UpdateColumnsOfTable"ruleResults"
type RuleResultsUpdateColumn string

const (
	// column name
	RuleResultsUpdateColumnCreatedAt RuleResultsUpdateColumn = "created_at"
	// column name
	RuleResultsUpdateColumnFileHistoryID RuleResultsUpdateColumn = "file_history_id"
	// column name
	RuleResultsUpdateColumnRuleID RuleResultsUpdateColumn = "rule_id"
	// column name
	RuleResultsUpdateColumnRuleResultID RuleResultsUpdateColumn = "rule_result_id"
	// column name
	RuleResultsUpdateColumnTag RuleResultsUpdateColumn = "tag"
	// column name
	RuleResultsUpdateColumnValue RuleResultsUpdateColumn = "value"
)

var AllRuleResultsUpdateColumn = []RuleResultsUpdateColumn{
	RuleResultsUpdateColumnCreatedAt,
	RuleResultsUpdateColumnFileHistoryID,
	RuleResultsUpdateColumnRuleID,
	RuleResultsUpdateColumnRuleResultID,
	RuleResultsUpdateColumnTag,
	RuleResultsUpdateColumnValue,
}

func (e RuleResultsUpdateColumn) IsValid() bool {
	switch e {
	case RuleResultsUpdateColumnCreatedAt, RuleResultsUpdateColumnFileHistoryID, RuleResultsUpdateColumnRuleID, RuleResultsUpdateColumnRuleResultID, RuleResultsUpdateColumnTag, RuleResultsUpdateColumnValue:
		return true
	}
	return false
}

func (e RuleResultsUpdateColumn) String() string {
	return string(e)
}

func (e *RuleResultsUpdateColumn) UnmarshalGQL(v interface{}) error {
	str, ok := v.(string)
	if !ok {
		return fmt.Errorf("enums must be strings")
	}

	*e = RuleResultsUpdateColumn(str)
	if !e.IsValid() {
		return fmt.Errorf("%s is not a valid rule_results_update_column", str)
	}
	return nil
}

func (e RuleResultsUpdateColumn) MarshalGQL(w io.Writer) {
	fmt.Fprint(w, strconv.Quote(e.String()))
}

// UniqueOrPrimaryKeyConstraintsOnTable"rules"
type RulesConstraint string

const (
	// unique or primary key constraint
	RulesConstraintRulesPkey RulesConstraint = "rules_pkey"
	// unique or primary key constraint
	RulesConstraintRulesPrincipalPriorityIgnoreKey RulesConstraint = "rules_principal_priority_ignore_key"
	// unique or primary key constraint
	RulesConstraintRulesPrincipalRuleIgnoreKey RulesConstraint = "rules_principal_rule_ignore_key"
)

var AllRulesConstraint = []RulesConstraint{
	RulesConstraintRulesPkey,
	RulesConstraintRulesPrincipalPriorityIgnoreKey,
	RulesConstraintRulesPrincipalRuleIgnoreKey,
}

func (e RulesConstraint) IsValid() bool {
	switch e {
	case RulesConstraintRulesPkey, RulesConstraintRulesPrincipalPriorityIgnoreKey, RulesConstraintRulesPrincipalRuleIgnoreKey:
		return true
	}
	return false
}

func (e RulesConstraint) String() string {
	return string(e)
}

func (e *RulesConstraint) UnmarshalGQL(v interface{}) error {
	str, ok := v.(string)
	if !ok {
		return fmt.Errorf("enums must be strings")
	}

	*e = RulesConstraint(str)
	if !e.IsValid() {
		return fmt.Errorf("%s is not a valid rules_constraint", str)
	}
	return nil
}

func (e RulesConstraint) MarshalGQL(w io.Writer) {
	fmt.Fprint(w, strconv.Quote(e.String()))
}

// SelectColumnsOfTable"rules"
type RulesSelectColumn string

const (
	// column name
	RulesSelectColumnIgnore RulesSelectColumn = "ignore"
	// column name
	RulesSelectColumnPrincipal RulesSelectColumn = "principal"
	// column name
	RulesSelectColumnPriority RulesSelectColumn = "priority"
	// column name
	RulesSelectColumnRule RulesSelectColumn = "rule"
	// column name
	RulesSelectColumnRuleID RulesSelectColumn = "rule_id"
	// column name
	RulesSelectColumnRuleType RulesSelectColumn = "rule_type"
)

var AllRulesSelectColumn = []RulesSelectColumn{
	RulesSelectColumnIgnore,
	RulesSelectColumnPrincipal,
	RulesSelectColumnPriority,
	RulesSelectColumnRule,
	RulesSelectColumnRuleID,
	RulesSelectColumnRuleType,
}

func (e RulesSelectColumn) IsValid() bool {
	switch e {
	case RulesSelectColumnIgnore, RulesSelectColumnPrincipal, RulesSelectColumnPriority, RulesSelectColumnRule, RulesSelectColumnRuleID, RulesSelectColumnRuleType:
		return true
	}
	return false
}

func (e RulesSelectColumn) String() string {
	return string(e)
}

func (e *RulesSelectColumn) UnmarshalGQL(v interface{}) error {
	str, ok := v.(string)
	if !ok {
		return fmt.Errorf("enums must be strings")
	}

	*e = RulesSelectColumn(str)
	if !e.IsValid() {
		return fmt.Errorf("%s is not a valid rules_select_column", str)
	}
	return nil
}

func (e RulesSelectColumn) MarshalGQL(w io.Writer) {
	fmt.Fprint(w, strconv.Quote(e.String()))
}

// UpdateColumnsOfTable"rules"
type RulesUpdateColumn string

const (
	// column name
	RulesUpdateColumnIgnore RulesUpdateColumn = "ignore"
	// column name
	RulesUpdateColumnPrincipal RulesUpdateColumn = "principal"
	// column name
	RulesUpdateColumnPriority RulesUpdateColumn = "priority"
	// column name
	RulesUpdateColumnRule RulesUpdateColumn = "rule"
	// column name
	RulesUpdateColumnRuleID RulesUpdateColumn = "rule_id"
	// column name
	RulesUpdateColumnRuleType RulesUpdateColumn = "rule_type"
)

var AllRulesUpdateColumn = []RulesUpdateColumn{
	RulesUpdateColumnIgnore,
	RulesUpdateColumnPrincipal,
	RulesUpdateColumnPriority,
	RulesUpdateColumnRule,
	RulesUpdateColumnRuleID,
	RulesUpdateColumnRuleType,
}

func (e RulesUpdateColumn) IsValid() bool {
	switch e {
	case RulesUpdateColumnIgnore, RulesUpdateColumnPrincipal, RulesUpdateColumnPriority, RulesUpdateColumnRule, RulesUpdateColumnRuleID, RulesUpdateColumnRuleType:
		return true
	}
	return false
}

func (e RulesUpdateColumn) String() string {
	return string(e)
}

func (e *RulesUpdateColumn) UnmarshalGQL(v interface{}) error {
	str, ok := v.(string)
	if !ok {
		return fmt.Errorf("enums must be strings")
	}

	*e = RulesUpdateColumn(str)
	if !e.IsValid() {
		return fmt.Errorf("%s is not a valid rules_update_column", str)
	}
	return nil
}

func (e RulesUpdateColumn) MarshalGQL(w io.Writer) {
	fmt.Fprint(w, strconv.Quote(e.String()))
}

// UniqueOrPrimaryKeyConstraintsOnTable"scans"
type ScansConstraint string

const (
	// unique or primary key constraint
	ScansConstraintScansPkey ScansConstraint = "scans_pkey"
)

var AllScansConstraint = []ScansConstraint{
	ScansConstraintScansPkey,
}

func (e ScansConstraint) IsValid() bool {
	switch e {
	case ScansConstraintScansPkey:
		return true
	}
	return false
}

func (e ScansConstraint) String() string {
	return string(e)
}

func (e *ScansConstraint) UnmarshalGQL(v interface{}) error {
	str, ok := v.(string)
	if !ok {
		return fmt.Errorf("enums must be strings")
	}

	*e = ScansConstraint(str)
	if !e.IsValid() {
		return fmt.Errorf("%s is not a valid scans_constraint", str)
	}
	return nil
}

func (e ScansConstraint) MarshalGQL(w io.Writer) {
	fmt.Fprint(w, strconv.Quote(e.String()))
}

// SelectColumnsOfTable"scans"
type ScansSelectColumn string

const (
	// column name
	ScansSelectColumnCompletedAt ScansSelectColumn = "completed_at"
	// column name
	ScansSelectColumnScanID ScansSelectColumn = "scan_id"
	// column name
	ScansSelectColumnStartedAt ScansSelectColumn = "started_at"
)

var AllScansSelectColumn = []ScansSelectColumn{
	ScansSelectColumnCompletedAt,
	ScansSelectColumnScanID,
	ScansSelectColumnStartedAt,
}

func (e ScansSelectColumn) IsValid() bool {
	switch e {
	case ScansSelectColumnCompletedAt, ScansSelectColumnScanID, ScansSelectColumnStartedAt:
		return true
	}
	return false
}

func (e ScansSelectColumn) String() string {
	return string(e)
}

func (e *ScansSelectColumn) UnmarshalGQL(v interface{}) error {
	str, ok := v.(string)
	if !ok {
		return fmt.Errorf("enums must be strings")
	}

	*e = ScansSelectColumn(str)
	if !e.IsValid() {
		return fmt.Errorf("%s is not a valid scans_select_column", str)
	}
	return nil
}

func (e ScansSelectColumn) MarshalGQL(w io.Writer) {
	fmt.Fprint(w, strconv.Quote(e.String()))
}

// UpdateColumnsOfTable"scans"
type ScansUpdateColumn string

const (
	// column name
	ScansUpdateColumnCompletedAt ScansUpdateColumn = "completed_at"
	// column name
	ScansUpdateColumnScanID ScansUpdateColumn = "scan_id"
	// column name
	ScansUpdateColumnStartedAt ScansUpdateColumn = "started_at"
)

var AllScansUpdateColumn = []ScansUpdateColumn{
	ScansUpdateColumnCompletedAt,
	ScansUpdateColumnScanID,
	ScansUpdateColumnStartedAt,
}

func (e ScansUpdateColumn) IsValid() bool {
	switch e {
	case ScansUpdateColumnCompletedAt, ScansUpdateColumnScanID, ScansUpdateColumnStartedAt:
		return true
	}
	return false
}

func (e ScansUpdateColumn) String() string {
	return string(e)
}

func (e *ScansUpdateColumn) UnmarshalGQL(v interface{}) error {
	str, ok := v.(string)
	if !ok {
		return fmt.Errorf("enums must be strings")
	}

	*e = ScansUpdateColumn(str)
	if !e.IsValid() {
		return fmt.Errorf("%s is not a valid scans_update_column", str)
	}
	return nil
}

func (e ScansUpdateColumn) MarshalGQL(w io.Writer) {
	fmt.Fprint(w, strconv.Quote(e.String()))
}
